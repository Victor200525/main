import os
import json
import math
import nltk
import pandas as pd
from datetime import datetime
from nltk.sentiment import SentimentIntensityAnalyzer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞–ø–æ–∫
INPUT_DIR = "input"
OUTPUT_DIR = "bitcoin_submissions"

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è Delta Lake, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
os.makedirs(OUTPUT_DIR, exist_ok=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è Vader
nltk.download('vader_lexicon', quiet=True)
sia = SentimentIntensityAnalyzer()

# –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input
for filename in os.listdir(INPUT_DIR):
    file_path = os.path.join(INPUT_DIR, filename)

    if not os.path.isfile(file_path):
        continue

    rows = []

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            for line_number, line in enumerate(file, 1):
                try:
                    data = json.loads(line)
                    selftext = data.get('selftext', '')
                    upvotes = data.get('score', 0)
                    date_created = data.get('created_utc', None)
                    num_of_comments = data.get('num_comments', 0)

                    # –ü—Ä–æ–ø—É—Å–∫ –ø—É—Å—Ç—ã—Ö –∏–ª–∏ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö
                    if not selftext.strip() or selftext.strip().lower() in {"[deleted]", "[removed]"}:
                        continue

                    try:
                        date = datetime.utcfromtimestamp(int(date_created)).date()
                    except Exception as e:
                        print(f"[{filename} | Line {line_number}] –û—à–∏–±–∫–∞ –¥–∞—Ç—ã: {e}")
                        continue

                    try:
                        sentiment = sia.polarity_scores(selftext)
                    except Exception as e:
                        print(f"[{filename} | Line {line_number}] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}")
                        sentiment = {}

                    compound = sentiment.get('compound', 0)

                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è score
                    norm_score_log = math.log1p(max(upvotes, 0))
                    norm_score_0_1 = norm_score_log / math.log1p(max(1, upvotes))

                    # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ—Å
                    weight_balanced = 0.5 * norm_score_0_1 + 0.5 * ((compound + 1) / 2)

                    rows.append({
                        'text': selftext,
                        'upvotes': upvotes,
                        'numofcomms': num_of_comments,
                        'sentiment': compound,
                        'Date': str(date),
                        'weight_balanced': weight_balanced,
                    })

                except json.JSONDecodeError as e:
                    print(f"[{filename} | Line {line_number}] JSON –æ—à–∏–±–∫–∞: {e}")
                except Exception as e:
                    print(f"[{filename} | Line {line_number}] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Delta Lake
        if rows:
            import polars as pl
            df = pl.DataFrame(rows)

            # –ò–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Delta ‚Äî –æ–±—â–µ–µ, –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å—Å—è
            df.write_delta(OUTPUT_DIR, mode="append")
            print(f"‚úÖ {filename} ‚Üí Delta Lake ({OUTPUT_DIR})")

        # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        os.remove(file_path)
        print(f"üóë –£–¥–∞–ª—ë–Ω {filename}")

    except FileNotFoundError:
        print(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filename}: {e}")
