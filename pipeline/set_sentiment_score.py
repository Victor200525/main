import json
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from datetime import datetime
import pandas as pd
import math
import os
import config

def set_sentiment():
    INPUT_DIR = config.INPUT_DIR
    OUTPUT_DIR = config.STAGE_DIR
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è Delta Lake, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    #os.makedirs(OUTPUT_DIR, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è Vader
    nltk.download('vader_lexicon', quiet=True)
    sia = SentimentIntensityAnalyzer()

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input
    for filename in os.listdir(INPUT_DIR):
        file_path = os.path.join(INPUT_DIR, filename)

        if not os.path.isfile(file_path):
            continue

        rows = []

        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                for line_number, line in enumerate(file, 1):
                    try:
                        data = json.loads(line)
                        selftext = data.get('selftext', '')
                        upvotes = data.get('score', 0)
                        date_created = data.get('created_utc', None)
                        num_of_comments = data.get('num_comments', 0)

                        # –ü—Ä–æ–ø—É—Å–∫ –ø—É—Å—Ç—ã—Ö –∏–ª–∏ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö
                        if not selftext.strip() or selftext.strip().lower() in {"[deleted]", "[removed]"}:
                            continue

                        try:
                            date = datetime.utcfromtimestamp(int(date_created)).date()
                        except Exception as e:
                            print(f"[{filename} | Line {line_number}] –û—à–∏–±–∫–∞ –¥–∞—Ç—ã: {e}")
                            continue

                        try:
                            sentiment = sia.polarity_scores(selftext)
                        except Exception as e:
                            print(f"[{filename} | Line {line_number}] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}")
                            sentiment = {}

                        compound = sentiment.get('compound', 0)

                        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è score
                        norm_score_log = math.log1p(max(upvotes, 0))
                        norm_score_0_1 = norm_score_log / math.log1p(max(1, upvotes))

                        # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ—Å
                        weight_balanced = 0.5 * norm_score_0_1 + 0.5 * ((compound + 1) / 2)

                        rows.append({
                            'text': selftext,
                            'upvotes': upvotes,
                            'numofcomms': num_of_comments,
                            'sentiment': compound,
                            'Date': str(date),
                            'weight_balanced': weight_balanced,
                        })

                    except json.JSONDecodeError as e:
                        print(f"[{filename} | Line {line_number}] JSON –æ—à–∏–±–∫–∞: {e}")
                    except Exception as e:
                        print(f"[{filename} | Line {line_number}] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Delta Lake
            if rows:
                import polars as pl
                df = pl.DataFrame(rows)

                # –ò–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Delta ‚Äî –æ–±—â–µ–µ, –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å—Å—è
                df.write_delta(OUTPUT_DIR, mode="append")
                print(f"‚úÖ {filename} ‚Üí Delta Lake ({OUTPUT_DIR})")

            # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
            #os.remove(file_path)
            #print(f"üóë –£–¥–∞–ª—ë–Ω {filename}")

        except FileNotFoundError:
            print(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filename}: {e}")

