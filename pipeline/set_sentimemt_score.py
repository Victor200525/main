import json
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from datetime import datetime
import pandas as pd
import math

def set_sentiment():
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞–ø–æ–∫
    INPUT_DIR = "./data/inputs"
    OUTPUT_DIR = "./data/outputs"

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è Delta Lake, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    #os.makedirs(OUTPUT_DIR, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è Vader
    nltk.download('vader_lexicon', quiet=True)
    sia = SentimentIntensityAnalyzer()

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input
    for filename in os.listdir(INPUT_DIR):
        file_path = os.path.join(INPUT_DIR, filename)

        if not os.path.isfile(file_path):
            continue

        rows = []

        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                for line_number, line in enumerate(file, 1):
                    try:
                        data = json.loads(line)
                        selftext = data.get('selftext', '')
                        upvotes = data.get('score', 0)
                        date_created = data.get('created_utc', None)
                        num_of_comments = data.get('num_comments', 0)

                        # –ü—Ä–æ–ø—É—Å–∫ –ø—É—Å—Ç—ã—Ö –∏–ª–∏ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö
                        if not selftext.strip() or selftext.strip().lower() in {"[deleted]", "[removed]"}:
                            continue

                        try:
                            date = datetime.utcfromtimestamp(int(date_created)).date()
                        except Exception as e:
                            print(f"[{filename} | Line {line_number}] –û—à–∏–±–∫–∞ –¥–∞—Ç—ã: {e}")
                            continue

                        try:
                            sentiment = sia.polarity_scores(selftext)
                        except Exception as e:
                            print(f"[{filename} | Line {line_number}] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}")
                            sentiment = {}

                        compound = sentiment.get('compound', 0)

                        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è score
                        norm_score_log = math.log1p(max(upvotes, 0))
                        norm_score_0_1 = norm_score_log / math.log1p(max(1, upvotes))

                        # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ—Å
                        weight_balanced = 0.5 * norm_score_0_1 + 0.5 * ((compound + 1) / 2)

                        rows.append({
                            'text': selftext,
                            'upvotes': upvotes,
                            'numofcomms': num_of_comments,
                            'sentiment': compound,
                            'Date': str(date),
                            'weight_balanced': weight_balanced,
                        })

                    except json.JSONDecodeError as e:
                        print(f"[{filename} | Line {line_number}] JSON –æ—à–∏–±–∫–∞: {e}")
                    except Exception as e:
                        print(f"[{filename} | Line {line_number}] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Delta Lake
            if rows:
                import polars as pl
                df = pl.DataFrame(rows)

                # –ò–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Delta ‚Äî –æ–±—â–µ–µ, –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å—Å—è
                df.write_delta(OUTPUT_DIR, mode="append")
                print(f"‚úÖ {filename} ‚Üí Delta Lake ({OUTPUT_DIR})")

            # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
            #os.remove(file_path)
            #print(f"üóë –£–¥–∞–ª—ë–Ω {filename}")

        except FileNotFoundError:
            print(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filename}: {e}")



def set_sentiment2():

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è Vader
    nltk.download('vader_lexicon', quiet=True)
    sia = SentimentIntensityAnalyzer()

    rows = []

    try:
        with open('Bitcoin_submissions', 'r', encoding='utf-8') as file:
            for line_number, line in enumerate(file, 1):
                try:
                    data = json.loads(line)
                    selftext = data.get('selftext', '')
                    upvotes = data.get('score', 0)
                    date_created = data.get('created_utc', None)
                    num_of_comments = data.get('num_comments', 0)

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ, —É–¥–∞–ª—ë–Ω–Ω—ã–µ –∏ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–º —É–¥–∞–ª—ë–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã
                    if not selftext.strip() or selftext.strip().lower() in {"[deleted]", "[removed]"}:
                        continue

                    try:
                        date = datetime.utcfromtimestamp(int(date_created)).date()
                    except Exception as e:
                        print(f"[Line {line_number}] Error parsing timestamp: {e}")
                        continue

                    try:
                        sentiment = sia.polarity_scores(selftext)
                    except Exception as e:
                        print(f"[Line {line_number}] Sentiment analysis error: {e}")
                        sentiment = {}

                    compound = sentiment.get('compound', 0)

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º score
                    norm_score_log = math.log1p(max(upvotes, 0))  # –ª–æ–≥–∞—Ä–∏—Ñ–º
                    norm_score_0_1 = norm_score_log / math.log1p( max(1, upvotes) )  # –≥—Ä—É–±–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ã–π max)


                    # 2. –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
                    weight_balanced = 0.5 * norm_score_0_1 + 0.5 * ((compound + 1) / 2)



                    rows.append({
                        'text': selftext,
                        'upvotes': upvotes,
                        'numofcomms': num_of_comments,
                        'sentiment': compound,
                        'Date': date,
                        'weight_balanced': weight_balanced,
                    })

                except json.JSONDecodeError as e:
                    print(f"[Line {line_number}] JSON decode error: {e}")
                except Exception as e:
                    print(f"[Line {line_number}] Unexpected error: {e}")

    except FileNotFoundError:
        print("File 'Bitcoin_submissions' not found.")
    except Exception as e:
        print(f"Error reading file: {e}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if rows:
        try:
            df = pd.DataFrame(rows)
            df.to_parquet('output.parquet', engine='pyarrow', index=False)
            print("Data successfully saved to 'output.parquet'.")
        except Exception as e:
            print(f"Error saving DataFrame to Parquet: {e}")
    else:
        print("No data collected; output file not created.")
